{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=-1>Licensed under the Apache License, Version 2.0 (the \\\"License\\\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at [https://www.apache.org/licenses/LICENSE-2.0](https://www.apache.org/licenses/LICENSE-2.0)\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \\\"AS IS\\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the License for the specific language governing permissions and limitations under the License.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/home/jupyter/.local/bin:/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# Set `PATH` to include the directory containing TFX CLI.\n",
    "PATH=%env PATH\n",
    "%env PATH=/home/jupyter/.local/bin:{PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFX version: 0.21.2\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import tfx; print('TFX version: {}'.format(tfx.__version__))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CI/CD for TFX pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will walk through authoring of a Cloud Build CI/CD workflow that automatically builds and deploys a TFX pipeline. You will also integrate your workflow with GitHub by setting up a trigger that starts the workflow when a new tag is applied to the GitHub repo hosting the pipeline's code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Cloud Build workflow\n",
    "Review the `cloudbuild.yaml` file to understand how the CI/CD workflow is implemented and how environment specific settings are abstracted using **Cloud Build** variables.\n",
    "\n",
    "The **Cloud Build** CI/CD workflow automates the steps you walked through manually during `lab-02`:\n",
    "1. Builds the custom TFX image to be used as a runtime execution environment for TFX components and as the AI Platform Training training container.\n",
    "1. Compiles the pipeline and uploads the pipeline to the KFP environment\n",
    "1. Pushes the custom TFX image to your project's **Container Registry**\n",
    "\n",
    "The **Cloud Build** workflow configuration uses both standard and custom [Cloud Build builders](https://cloud.google.com/cloud-build/docs/cloud-builders). The custom builder encapsulates **TFX CLI**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring environment settings\n",
    "\n",
    "Update  the below constants  with the settings reflecting your lab environment. \n",
    "\n",
    "- `GCP_REGION` - the compute region for AI Platform Training and Prediction\n",
    "- `ARTIFACT_STORE` - the GCS bucket created during installation of AI Platform Pipelines. The bucket name starts with the `hostedkfp-default-` prefix.\n",
    "- `ENDPOINT` - set the `ENDPOINT` constant to the endpoint to your AI Platform Pipelines instance. Then endpoint to the AI Platform Pipelines instance can be found on the [AI Platform Pipelines](https://console.cloud.google.com/ai-platform/pipelines/clusters) page in the Google Cloud Console.\n",
    "\n",
    "1. Open the *SETTINGS* for your instance\n",
    "2. Use the value of the `host` variable in the *Connect to this Kubeflow Pipelines instance from a Python client via Kubeflow Pipelines SKD* section of the *SETTINGS* window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCP_REGION = 'us-central1'\n",
    "ARTIFACT_STORE_URI = 'gs://hostedkfp-default-ekiduphg3h'\n",
    "ENDPOINT = '3b661cff0725e5af-dot-us-central2.pipelines.googleusercontent.com'\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the TFX CLI builder\n",
    "### Review the Dockerfile describing the TFX CLI builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM gcr.io/deeplearning-platform-release/tf2-cpu.2-1\n",
      "COPY requirements.txt .\n",
      "RUN python -m pip install -U -r requirements.txt\n",
      "\n",
      "ENTRYPOINT [\"tfx\"]\n"
     ]
    }
   ],
   "source": [
    "!cat tfx-cli/Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas<1.0.0\n",
      "tfx==0.21.2\n",
      "kfp==0.2.5\n"
     ]
    }
   ],
   "source": [
    "!cat tfx-cli/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the image and push it to your project's **Container Registry**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME='tfx-cli'\n",
    "TAG='latest'\n",
    "IMAGE_URI='gcr.io/{}/{}:{}'.format(PROJECT_ID, IMAGE_NAME, TAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 3 file(s) totalling 330 bytes before compression.\n",
      "Uploading tarball of [tfx-cli] to [gs://mlops-workshop_cloudbuild/source/1585191841.89-cb0282d2d9914021a1844280ed1ad9b6.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/mlops-workshop/builds/84439324-8b81-4c2a-9a84-8ead11ec8466].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/84439324-8b81-4c2a-9a84-8ead11ec8466?project=745302968357].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"84439324-8b81-4c2a-9a84-8ead11ec8466\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://mlops-workshop_cloudbuild/source/1585191841.89-cb0282d2d9914021a1844280ed1ad9b6.tgz#1585191842208349\n",
      "Copying gs://mlops-workshop_cloudbuild/source/1585191841.89-cb0282d2d9914021a1844280ed1ad9b6.tgz#1585191842208349...\n",
      "/ [1 files][  367.0 B/  367.0 B]                                                \n",
      "Operation completed over 1 objects/367.0 B.                                      \n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  4.608kB\n",
      "Step 1/4 : FROM gcr.io/deeplearning-platform-release/tf2-cpu.2-1\n",
      "latest: Pulling from deeplearning-platform-release/tf2-cpu.2-1\n",
      "423ae2b273f4: Already exists\n",
      "de83a2304fa1: Already exists\n",
      "f9a83bce3af0: Already exists\n",
      "b6b53be908de: Already exists\n",
      "b2712ee52c8a: Pulling fs layer\n",
      "ea5f203ec613: Pulling fs layer\n",
      "03c59c37590c: Pulling fs layer\n",
      "7f1f0de4c26d: Pulling fs layer\n",
      "acbb498b3663: Pulling fs layer\n",
      "e902a9253d07: Pulling fs layer\n",
      "f840da7abf6f: Pulling fs layer\n",
      "7df56b5a1b90: Pulling fs layer\n",
      "a2724a388c5b: Pulling fs layer\n",
      "444a423384b3: Pulling fs layer\n",
      "c8782b778b9f: Pulling fs layer\n",
      "8e8ac5d0d6f3: Pulling fs layer\n",
      "455723d7f082: Pulling fs layer\n",
      "7f1f0de4c26d: Waiting\n",
      "acbb498b3663: Waiting\n",
      "e902a9253d07: Waiting\n",
      "f840da7abf6f: Waiting\n",
      "7df56b5a1b90: Waiting\n",
      "a2724a388c5b: Waiting\n",
      "444a423384b3: Waiting\n",
      "c8782b778b9f: Waiting\n",
      "8e8ac5d0d6f3: Waiting\n",
      "455723d7f082: Waiting\n",
      "03c59c37590c: Verifying Checksum\n",
      "03c59c37590c: Download complete\n",
      "ea5f203ec613: Verifying Checksum\n",
      "ea5f203ec613: Download complete\n",
      "acbb498b3663: Verifying Checksum\n",
      "acbb498b3663: Download complete\n",
      "7f1f0de4c26d: Verifying Checksum\n",
      "7f1f0de4c26d: Download complete\n",
      "e902a9253d07: Verifying Checksum\n",
      "e902a9253d07: Download complete\n",
      "f840da7abf6f: Verifying Checksum\n",
      "f840da7abf6f: Download complete\n",
      "7df56b5a1b90: Verifying Checksum\n",
      "7df56b5a1b90: Download complete\n",
      "a2724a388c5b: Verifying Checksum\n",
      "a2724a388c5b: Download complete\n",
      "444a423384b3: Verifying Checksum\n",
      "444a423384b3: Download complete\n",
      "8e8ac5d0d6f3: Verifying Checksum\n",
      "8e8ac5d0d6f3: Download complete\n",
      "455723d7f082: Verifying Checksum\n",
      "455723d7f082: Download complete\n",
      "b2712ee52c8a: Verifying Checksum\n",
      "b2712ee52c8a: Download complete\n",
      "c8782b778b9f: Verifying Checksum\n",
      "c8782b778b9f: Download complete\n",
      "b2712ee52c8a: Pull complete\n",
      "ea5f203ec613: Pull complete\n",
      "03c59c37590c: Pull complete\n",
      "7f1f0de4c26d: Pull complete\n",
      "acbb498b3663: Pull complete\n",
      "e902a9253d07: Pull complete\n",
      "f840da7abf6f: Pull complete\n",
      "7df56b5a1b90: Pull complete\n",
      "a2724a388c5b: Pull complete\n",
      "444a423384b3: Pull complete\n",
      "c8782b778b9f: Pull complete\n",
      "8e8ac5d0d6f3: Pull complete\n",
      "455723d7f082: Pull complete\n",
      "Digest: sha256:013c0f1b279e1d58670f8f09478414148c314a460e1b15b5880c702b942b3e19\n",
      "Status: Downloaded newer image for gcr.io/deeplearning-platform-release/tf2-cpu.2-1:latest\n",
      " ---> 4f3009408e35\n",
      "Step 2/4 : COPY requirements.txt .\n",
      " ---> 3a58531dc36f\n",
      "Step 3/4 : RUN python -m pip install -U -r requirements.txt\n",
      " ---> Running in b890ca51cb72\n",
      "Collecting pandas<1.0.0\n",
      "  Downloading pandas-0.25.3-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n",
      "Collecting tfx==0.21.2\n",
      "  Downloading tfx-0.21.2-py3-none-any.whl (1.1 MB)\n",
      "Collecting kfp==0.2.5\n",
      "  Downloading kfp-0.2.5.tar.gz (116 kB)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas<1.0.0->-r requirements.txt (line 1)) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from pandas<1.0.0->-r requirements.txt (line 1)) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas<1.0.0->-r requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: protobuf<4,>=3.7 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.2->-r requirements.txt (line 2)) (3.11.3)\n",
      "Collecting apache-beam[gcp]<2.18,>=2.17\n",
      "  Downloading apache_beam-2.17.0-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
      "Collecting tensorflow-model-analysis<0.22,>=0.21.4\n",
      "  Downloading tensorflow_model_analysis-0.21.6-py3-none-any.whl (1.5 MB)\n",
      "Collecting pyarrow<0.16,>=0.15\n",
      "  Downloading pyarrow-0.15.1-cp37-cp37m-manylinux2010_x86_64.whl (59.2 MB)\n",
      "Requirement already satisfied, skipping upgrade: six<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.2->-r requirements.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: jinja2<3,>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.2->-r requirements.txt (line 2)) (2.11.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-serving-api<3,>=1.15 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.2->-r requirements.txt (line 2)) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml<6,>=5 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.2->-r requirements.txt (line 2)) (5.3)\n",
      "Collecting tfx-bsl<0.22,>=0.21.3\n",
      "  Downloading tfx_bsl-0.21.4-cp37-cp37m-manylinux2010_x86_64.whl (1.9 MB)\n",
      "Requirement already satisfied, skipping upgrade: google-api-python-client<2,>=1.7.8 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.2->-r requirements.txt (line 2)) (1.7.11)\n",
      "Requirement already satisfied, skipping upgrade: click<8,>=7 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.2->-r requirements.txt (line 2)) (7.0)\n",
      "Collecting absl-py<0.9,>=0.1.6\n",
      "  Downloading absl-py-0.8.1.tar.gz (103 kB)\n",
      "Collecting tensorflow-data-validation<0.22,>=0.21.4\n",
      "  Downloading tensorflow_data_validation-0.21.5-cp37-cp37m-manylinux2010_x86_64.whl (2.4 MB)\n",
      "Collecting grpcio!=1.27.2,<2,>=1.25\n",
      "  Downloading grpcio-1.27.1-cp37-cp37m-manylinux2010_x86_64.whl (2.7 MB)\n",
      "Requirement already satisfied, skipping upgrade: docker<5,>=4.1 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.2->-r requirements.txt (line 2)) (4.2.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow<3,>=1.15 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.2->-r requirements.txt (line 2)) (2.1.0)\n",
      "Collecting tensorflow-transform<0.22,>=0.21.2\n",
      "  Downloading tensorflow-transform-0.21.2.tar.gz (241 kB)\n",
      "Collecting ml-metadata<0.22,>=0.21.2\n",
      "  Downloading ml_metadata-0.21.2-cp37-cp37m-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Collecting urllib3<1.25,>=1.15\n",
      "  Downloading urllib3-1.24.3-py2.py3-none-any.whl (118 kB)\n",
      "Requirement already satisfied, skipping upgrade: certifi in /opt/conda/lib/python3.7/site-packages (from kfp==0.2.5->-r requirements.txt (line 3)) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-storage>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from kfp==0.2.5->-r requirements.txt (line 3)) (1.26.0)\n",
      "Collecting kubernetes<=10.0.0,>=8.0.0\n",
      "  Downloading kubernetes-10.0.0-py2.py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied, skipping upgrade: PyJWT>=1.6.4 in /opt/conda/lib/python3.7/site-packages (from kfp==0.2.5->-r requirements.txt (line 3)) (1.7.1)\n",
      "Requirement already satisfied, skipping upgrade: cryptography>=2.4.2 in /opt/conda/lib/python3.7/site-packages (from kfp==0.2.5->-r requirements.txt (line 3)) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: google-auth>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from kfp==0.2.5->-r requirements.txt (line 3)) (1.11.2)\n",
      "Collecting requests_toolbelt>=0.8.0\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "Collecting cloudpickle==1.1.1\n",
      "  Downloading cloudpickle-1.1.1-py2.py3-none-any.whl (17 kB)\n",
      "Collecting kfp-server-api<=0.1.40,>=0.1.18\n",
      "  Downloading kfp-server-api-0.1.40.tar.gz (38 kB)\n",
      "Collecting argo-models==2.2.1a\n",
      "  Downloading argo-models-2.2.1a0.tar.gz (28 kB)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kfp==0.2.5->-r requirements.txt (line 3)) (3.2.0)\n",
      "Collecting tabulate==0.8.3\n",
      "  Downloading tabulate-0.8.3.tar.gz (46 kB)\n",
      "Collecting Deprecated\n",
      "  Downloading Deprecated-1.2.7-py2.py3-none-any.whl (8.3 kB)\n",
      "Collecting strip-hints\n",
      "  Downloading strip-hints-0.1.8.tar.gz (27 kB)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf<4,>=3.7->tfx==0.21.2->-r requirements.txt (line 2)) (45.2.0.post20200209)\n",
      "Collecting httplib2<=0.12.0,>=0.8\n",
      "  Downloading httplib2-0.12.0.tar.gz (218 kB)\n",
      "Collecting dill<0.3.1,>=0.3.0\n",
      "  Downloading dill-0.3.0.tar.gz (151 kB)\n",
      "Collecting fastavro<0.22,>=0.21.4\n",
      "  Downloading fastavro-0.21.24-cp37-cp37m-manylinux1_x86_64.whl (1.2 MB)\n",
      "Collecting crcmod<2.0,>=1.7\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "Collecting pymongo<4.0.0,>=3.8.0\n",
      "  Downloading pymongo-3.10.1-cp37-cp37m-manylinux2014_x86_64.whl (462 kB)\n",
      "Collecting oauth2client<4,>=2.0.1\n",
      "  Downloading oauth2client-3.0.0.tar.gz (77 kB)\n",
      "Requirement already satisfied, skipping upgrade: future<1.0.0,>=0.16.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<2.18,>=2.17->tfx==0.21.2->-r requirements.txt (line 2)) (0.18.2)\n",
      "Requirement already satisfied, skipping upgrade: pydot<2,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<2.18,>=2.17->tfx==0.21.2->-r requirements.txt (line 2)) (1.4.1)\n",
      "Collecting mock<3.0.0,>=1.0.1\n",
      "  Downloading mock-2.0.0-py2.py3-none-any.whl (56 kB)\n",
      "Collecting hdfs<3.0.0,>=2.1.0\n",
      "  Downloading hdfs-2.5.8.tar.gz (41 kB)\n",
      "Collecting avro-python3<2.0.0,>=1.8.1; python_version >= \"3.0\"\n",
      "  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n",
      "Collecting google-cloud-bigtable<1.1.0,>=0.31.1; extra == \"gcp\"\n",
      "  Downloading google_cloud_bigtable-1.0.0-py2.py3-none-any.whl (232 kB)\n",
      "Collecting google-cloud-bigquery<1.18.0,>=1.6.0; extra == \"gcp\"\n",
      "  Downloading google_cloud_bigquery-1.17.1-py2.py3-none-any.whl (142 kB)\n",
      "Collecting google-apitools<0.5.29,>=0.5.28; extra == \"gcp\"\n",
      "  Downloading google-apitools-0.5.28.tar.gz (172 kB)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-core<2,>=0.28.1; extra == \"gcp\" in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<2.18,>=2.17->tfx==0.21.2->-r requirements.txt (line 2)) (1.3.0)\n",
      "Collecting cachetools<4,>=3.1.0; extra == \"gcp\"\n",
      "  Downloading cachetools-3.1.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting google-cloud-datastore<1.8.0,>=1.7.1; extra == \"gcp\"\n",
      "  Downloading google_cloud_datastore-1.7.4-py2.py3-none-any.whl (82 kB)\n",
      "Collecting google-cloud-pubsub<1.1.0,>=0.39.0; extra == \"gcp\"\n",
      "  Downloading google_cloud_pubsub-1.0.2-py2.py3-none-any.whl (118 kB)\n",
      "Requirement already satisfied, skipping upgrade: jupyter<2,>=1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-metadata<0.22,>=0.21 in /opt/conda/lib/python3.7/site-packages (from tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (0.21.1)\n",
      "Requirement already satisfied, skipping upgrade: ipywidgets<8,>=7 in /opt/conda/lib/python3.7/site-packages (from tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (7.5.1)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2<3,>=2.7.3->tfx==0.21.2->-r requirements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->tfx==0.21.2->-r requirements.txt (line 2)) (0.0.3)\n",
      "Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->tfx==0.21.2->-r requirements.txt (line 2)) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib<0.15,>=0.12 in /opt/conda/lib/python3.7/site-packages (from tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (0.14.1)\n",
      "Collecting scikit-learn<0.22,>=0.18\n",
      "  Downloading scikit_learn-0.21.3-cp37-cp37m-manylinux1_x86_64.whl (6.7 MB)\n",
      "Requirement already satisfied, skipping upgrade: ipython>=5 in /opt/conda/lib/python3.7/site-packages (from tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (7.12.0)\n",
      "Requirement already satisfied, skipping upgrade: requests!=2.18.0,>=2.14.2 in /opt/conda/lib/python3.7/site-packages (from docker<5,>=4.1->tfx==0.21.2->-r requirements.txt (line 2)) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: websocket-client>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from docker<5,>=4.1->tfx==0.21.2->-r requirements.txt (line 2)) (0.57.0)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=1.15->tfx==0.21.2->-r requirements.txt (line 2)) (0.1.8)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=1.15->tfx==0.21.2->-r requirements.txt (line 2)) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=1.15->tfx==0.21.2->-r requirements.txt (line 2)) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=1.15->tfx==0.21.2->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=1.15->tfx==0.21.2->-r requirements.txt (line 2)) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<2.2.0,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=1.15->tfx==0.21.2->-r requirements.txt (line 2)) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=1.15->tfx==0.21.2->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=1.15->tfx==0.21.2->-r requirements.txt (line 2)) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=1.15->tfx==0.21.2->-r requirements.txt (line 2)) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=1.15->tfx==0.21.2->-r requirements.txt (line 2)) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=1.15->tfx==0.21.2->-r requirements.txt (line 2)) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: google-resumable-media<0.6dev,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage>=1.13.0->kfp==0.2.5->-r requirements.txt (line 3)) (0.5.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from kubernetes<=10.0.0,>=8.0.0->kfp==0.2.5->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: cffi!=1.11.3,>=1.8 in /opt/conda/lib/python3.7/site-packages (from cryptography>=2.4.2->kfp==0.2.5->-r requirements.txt (line 3)) (1.13.2)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==0.2.5->-r requirements.txt (line 3)) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==0.2.5->-r requirements.txt (line 3)) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kfp==0.2.5->-r requirements.txt (line 3)) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kfp==0.2.5->-r requirements.txt (line 3)) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kfp==0.2.5->-r requirements.txt (line 3)) (0.15.7)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.7 in /opt/conda/lib/python3.7/site-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]<2.18,>=2.17->tfx==0.21.2->-r requirements.txt (line 2)) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.1.4 in /opt/conda/lib/python3.7/site-packages (from pydot<2,>=1.2.0->apache-beam[gcp]<2.18,>=2.17->tfx==0.21.2->-r requirements.txt (line 2)) (2.4.6)\n",
      "Collecting pbr>=0.11\n",
      "  Downloading pbr-5.4.4-py2.py3-none-any.whl (110 kB)\n",
      "Collecting docopt\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Requirement already satisfied, skipping upgrade: grpc-google-iam-v1<0.13dev,>=0.12.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigtable<1.1.0,>=0.31.1; extra == \"gcp\"->apache-beam[gcp]<2.18,>=2.17->tfx==0.21.2->-r requirements.txt (line 2)) (0.12.3)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core[grpc]<2.0.0dev,>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigtable<1.1.0,>=0.31.1; extra == \"gcp\"->apache-beam[gcp]<2.18,>=2.17->tfx==0.21.2->-r requirements.txt (line 2)) (1.16.0)\n",
      "Collecting fasteners>=0.14\n",
      "  Downloading fasteners-0.15-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied, skipping upgrade: qtconsole in /opt/conda/lib/python3.7/site-packages (from jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (4.6.0)\n",
      "Requirement already satisfied, skipping upgrade: notebook in /opt/conda/lib/python3.7/site-packages (from jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (6.0.3)\n",
      "Requirement already satisfied, skipping upgrade: nbconvert in /opt/conda/lib/python3.7/site-packages (from jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (5.6.1)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-console in /opt/conda/lib/python3.7/site-packages (from jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (6.0.0)\n",
      "Requirement already satisfied, skipping upgrade: ipykernel in /opt/conda/lib/python3.7/site-packages (from jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (5.1.4)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos in /opt/conda/lib/python3.7/site-packages (from tensorflow-metadata<0.22,>=0.21->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (1.51.0)\n",
      "Requirement already satisfied, skipping upgrade: traitlets>=4.3.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (4.3.3)\n",
      "Requirement already satisfied, skipping upgrade: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (3.5.1)\n",
      "Requirement already satisfied, skipping upgrade: nbformat>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (5.0.4)\n",
      "Requirement already satisfied, skipping upgrade: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=5->tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (0.7.5)\n",
      "Requirement already satisfied, skipping upgrade: jedi>=0.10 in /opt/conda/lib/python3.7/site-packages (from ipython>=5->tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.7/site-packages (from ipython>=5->tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (4.8.0)\n",
      "Requirement already satisfied, skipping upgrade: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=5->tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (2.0.10)\n",
      "Requirement already satisfied, skipping upgrade: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=5->tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (0.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=5->tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (2.5.2)\n",
      "Requirement already satisfied, skipping upgrade: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=5->tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (4.4.1)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests!=2.18.0,>=2.14.2->docker<5,>=4.1->tfx==0.21.2->-r requirements.txt (line 2)) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests!=2.18.0,>=2.14.2->docker<5,>=4.1->tfx==0.21.2->-r requirements.txt (line 2)) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow<3,>=1.15->tfx==0.21.2->-r requirements.txt (line 2)) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<3,>=1.15->tfx==0.21.2->-r requirements.txt (line 2)) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<3,>=1.15->tfx==0.21.2->-r requirements.txt (line 2)) (3.2.1)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<3,>=1.15->tfx==0.21.2->-r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->kubernetes<=10.0.0,>=8.0.0->kfp==0.2.5->-r requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.4.2->kfp==0.2.5->-r requirements.txt (line 3)) (2.19)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kfp==0.2.5->-r requirements.txt (line 3)) (3.0.0)\n",
      "Collecting monotonic>=0.1\n",
      "  Downloading monotonic-1.5-py2.py3-none-any.whl (5.3 kB)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-core in /opt/conda/lib/python3.7/site-packages (from qtconsole->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (4.6.3)\n",
      "Requirement already satisfied, skipping upgrade: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from qtconsole->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-client>=4.1 in /opt/conda/lib/python3.7/site-packages (from qtconsole->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (6.0.0)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=5.0 in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (6.0.3)\n",
      "Requirement already satisfied, skipping upgrade: prometheus-client in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (0.7.1)\n",
      "Requirement already satisfied, skipping upgrade: terminado>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (0.8.3)\n",
      "Requirement already satisfied, skipping upgrade: Send2Trash in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: pyzmq>=17 in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (19.0.0)\n",
      "Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (0.3)\n",
      "Requirement already satisfied, skipping upgrade: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (0.8.4)\n",
      "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (1.4.2)\n",
      "Requirement already satisfied, skipping upgrade: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: parso>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.10->ipython>=5->tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=5->tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5->tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (0.1.8)\n",
      "Requirement already satisfied, skipping upgrade: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.2->-r requirements.txt (line 2)) (0.5.1)\n",
      "Building wheels for collected packages: kfp, absl-py, tensorflow-transform, kfp-server-api, argo-models, tabulate, strip-hints, httplib2, dill, crcmod, oauth2client, hdfs, avro-python3, google-apitools, docopt\n",
      "  Building wheel for kfp (setup.py): started\n",
      "  Building wheel for kfp (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp: filename=kfp-0.2.5-py3-none-any.whl size=159978 sha256=88eba09a19d721c93f8772b8ce652ec62da7d588d04cc8a06d814ad01fbfd435\n",
      "  Stored in directory: /root/.cache/pip/wheels/98/74/7e/0a882d654bdf82d039460ab5c6adf8724ae56e277de7c0eaea\n",
      "  Building wheel for absl-py (setup.py): started\n",
      "  Building wheel for absl-py (setup.py): finished with status 'done'\n",
      "  Created wheel for absl-py: filename=absl_py-0.8.1-py3-none-any.whl size=121165 sha256=9e25830dbe71dabbbfe6775123872f900032f97bfc51511725f69828d1c82ba9\n",
      "  Stored in directory: /root/.cache/pip/wheels/46/91/e3/0fced4f5fbc0a051a5667096826186c9ff60f2d0e9bf0f1cdc\n",
      "  Building wheel for tensorflow-transform (setup.py): started\n",
      "  Building wheel for tensorflow-transform (setup.py): finished with status 'done'\n",
      "  Created wheel for tensorflow-transform: filename=tensorflow_transform-0.21.2-py3-none-any.whl size=301093 sha256=056f43e6e615f1544f5086eecc26d870b7ed9cf5d76771dd6793ced1e0ea4354\n",
      "  Stored in directory: /root/.cache/pip/wheels/a2/23/3c/d1e25657c6d156f96a5157e253309f81f5cfe2327e32290967\n",
      "  Building wheel for kfp-server-api (setup.py): started\n",
      "  Building wheel for kfp-server-api (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp-server-api: filename=kfp_server_api-0.1.40-py3-none-any.whl size=102468 sha256=fa7fcf0a620e293dc23d3fdb523ad22eba355fb4b7cc631d1588da994bb0f602\n",
      "  Stored in directory: /root/.cache/pip/wheels/01/e3/43/3972dea76ee89e35f090b313817089043f2609236cf560069d\n",
      "  Building wheel for argo-models (setup.py): started\n",
      "  Building wheel for argo-models (setup.py): finished with status 'done'\n",
      "  Created wheel for argo-models: filename=argo_models-2.2.1a0-py3-none-any.whl size=57307 sha256=c5578700150cfae916bce5366ea541f1da458ef6898daa5635c2326fed8bdd57\n",
      "  Stored in directory: /root/.cache/pip/wheels/a9/4b/fd/cdd013bd2ad1a7162ecfaf954e9f1bb605174a20e3c02016b7\n",
      "  Building wheel for tabulate (setup.py): started\n",
      "  Building wheel for tabulate (setup.py): finished with status 'done'\n",
      "  Created wheel for tabulate: filename=tabulate-0.8.3-py3-none-any.whl size=23378 sha256=dc5c9ad2e5d5beb06295bb93bf309ce7e6683ec5a9a996faa60a2c8aedb36978\n",
      "  Stored in directory: /root/.cache/pip/wheels/b8/a2/a6/812a8a9735b090913e109133c7c20aaca4cf07e8e18837714f\n",
      "  Building wheel for strip-hints (setup.py): started\n",
      "  Building wheel for strip-hints (setup.py): finished with status 'done'\n",
      "  Created wheel for strip-hints: filename=strip_hints-0.1.8-py2.py3-none-any.whl size=19616 sha256=c7faa08a3c9879d3e698c066f120df0c9c29a33c0095dd4db22e143de32d130c\n",
      "  Stored in directory: /root/.cache/pip/wheels/45/d9/0c/4a8bfd636665a0969edf94d03397e7b01b23bd2129f7b09d4b\n",
      "  Building wheel for httplib2 (setup.py): started\n",
      "  Building wheel for httplib2 (setup.py): finished with status 'done'\n",
      "  Created wheel for httplib2: filename=httplib2-0.12.0-py3-none-any.whl size=93464 sha256=c5e9e585885d927218d731fecbde775df2d857a80679b88cb067daabd519c92c\n",
      "  Stored in directory: /root/.cache/pip/wheels/0d/e7/b6/0dd30343ceca921cfbd91f355041bd9c69e0f40b49f25b7b8a\n",
      "  Building wheel for dill (setup.py): started\n",
      "  Building wheel for dill (setup.py): finished with status 'done'\n",
      "  Created wheel for dill: filename=dill-0.3.0-py3-none-any.whl size=77511 sha256=72fbe18eaeb5bcb82dc6dee06c17cb2f6b9132ce62c42956431159f0fb815fb6\n",
      "  Stored in directory: /root/.cache/pip/wheels/6a/3c/26/1fcc712c80b81fe1859f2dda4415f180fe9ef3ebe9f5e202e4\n",
      "  Building wheel for crcmod (setup.py): started\n",
      "  Building wheel for crcmod (setup.py): finished with status 'done'\n",
      "  Created wheel for crcmod: filename=crcmod-1.7-cp37-cp37m-linux_x86_64.whl size=36466 sha256=0e856ecd91fd66cf0848f03a45aa782bfc323c509e2236ffcda37530c1cafd59\n",
      "  Stored in directory: /root/.cache/pip/wheels/dc/9a/e9/49e627353476cec8484343c4ab656f1e0d783ee77b9dde2d1f\n",
      "  Building wheel for oauth2client (setup.py): started\n",
      "  Building wheel for oauth2client (setup.py): finished with status 'done'\n",
      "  Created wheel for oauth2client: filename=oauth2client-3.0.0-py3-none-any.whl size=106383 sha256=9610cb6afc6ad1192e4c3352d9cf2860b8f6fdfe3746d3201e77ffb42f84dab3\n",
      "  Stored in directory: /root/.cache/pip/wheels/86/73/7a/3b3f76a2142176605ff38fbca574327962c71e25a43197a4c1\n",
      "  Building wheel for hdfs (setup.py): started\n",
      "  Building wheel for hdfs (setup.py): finished with status 'done'\n",
      "  Created wheel for hdfs: filename=hdfs-2.5.8-py3-none-any.whl size=33213 sha256=54a952868b3b27195e770220a14a0dd3e7bc7f9ddf2b6fbd6401d0b0c5d750d9\n",
      "  Stored in directory: /root/.cache/pip/wheels/0a/7d/38/ea4eaf831518e6cd867b515b88919a9785eb66f11def5ab859\n",
      "  Building wheel for avro-python3 (setup.py): started\n",
      "  Building wheel for avro-python3 (setup.py): finished with status 'done'\n",
      "  Created wheel for avro-python3: filename=avro_python3-1.9.2.1-py3-none-any.whl size=43513 sha256=acc22a8c797a6505ad0de7736e2278a4de657fff583c698ae38e66572cc259ec\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/49/5f/fdb5b9d85055c478213e0158ac122b596816149a02d82e0ab1\n",
      "  Building wheel for google-apitools (setup.py): started\n",
      "  Building wheel for google-apitools (setup.py): finished with status 'done'\n",
      "  Created wheel for google-apitools: filename=google_apitools-0.5.28-py3-none-any.whl size=130110 sha256=7f07edd4d68d019a5b23edeab9e2cc3e7482e6d73efd8ef201a4af8eaa44df15\n",
      "  Stored in directory: /root/.cache/pip/wheels/34/3b/69/ecd8e6ae89d9d71102a58962c29faa7a9467ba45f99f205920\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13704 sha256=f617c131b0affc563d123eafcc59dfc211251b70d4f7bdbc1f0bed6f62e9af79\n",
      "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
      "Successfully built kfp absl-py tensorflow-transform kfp-server-api argo-models tabulate strip-hints httplib2 dill crcmod oauth2client hdfs avro-python3 google-apitools docopt\n",
      "\u001b[91mERROR: papermill 2.0.0 requires black; python_version >= \"3.6\", which is not installed.\n",
      "\u001b[0m\u001b[91mERROR: witwidget 1.5.1 has requirement oauth2client>=4.1.3, but you'll have oauth2client 3.0.0 which is incompatible.\n",
      "\u001b[0m\u001b[91mERROR: tensorflow-probability 0.9.0 has requirement cloudpickle>=1.2.2, but you'll have cloudpickle 1.1.1 which is incompatible.\n",
      "\u001b[0m\u001b[91mERROR: google-cloud-bigquery 1.17.1 has requirement google-resumable-media<0.5.0dev,>=0.3.1, but you'll have google-resumable-media 0.5.0 which is incompatible.\n",
      "\u001b[0m\u001b[91mERROR: datalab 1.1.5 has requirement pandas-profiling==1.4.0, but you'll have pandas-profiling 2.4.0 which is incompatible.\n",
      "\u001b[0mInstalling collected packages: pandas, httplib2, dill, fastavro, crcmod, pymongo, grpcio, oauth2client, pyarrow, pbr, mock, docopt, hdfs, avro-python3, google-cloud-bigtable, google-cloud-bigquery, monotonic, fasteners, google-apitools, cachetools, google-cloud-datastore, google-cloud-pubsub, apache-beam, absl-py, tfx-bsl, tensorflow-model-analysis, tensorflow-transform, scikit-learn, tensorflow-data-validation, ml-metadata, tfx, urllib3, kubernetes, requests-toolbelt, cloudpickle, kfp-server-api, argo-models, tabulate, Deprecated, strip-hints, kfp\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.0.1\n",
      "    Uninstalling pandas-1.0.1:\n",
      "      Successfully uninstalled pandas-1.0.1\n",
      "  Attempting uninstall: httplib2\n",
      "    Found existing installation: httplib2 0.17.0\n",
      "    Uninstalling httplib2-0.17.0:\n",
      "      Successfully uninstalled httplib2-0.17.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.1.1\n",
      "    Uninstalling dill-0.3.1.1:\n",
      "      Successfully uninstalled dill-0.3.1.1\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.27.2\n",
      "    Uninstalling grpcio-1.27.2:\n",
      "      Successfully uninstalled grpcio-1.27.2\n",
      "  Attempting uninstall: oauth2client\n",
      "    Found existing installation: oauth2client 4.1.3\n",
      "    Uninstalling oauth2client-4.1.3:\n",
      "      Successfully uninstalled oauth2client-4.1.3\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 0.16.0\n",
      "    Uninstalling pyarrow-0.16.0:\n",
      "      Successfully uninstalled pyarrow-0.16.0\n",
      "  Attempting uninstall: mock\n",
      "    Found existing installation: mock 3.0.5\n",
      "    Uninstalling mock-3.0.5:\n",
      "      Successfully uninstalled mock-3.0.5\n",
      "  Attempting uninstall: google-cloud-bigtable\n",
      "    Found existing installation: google-cloud-bigtable 1.2.1\n",
      "    Uninstalling google-cloud-bigtable-1.2.1:\n",
      "      Successfully uninstalled google-cloud-bigtable-1.2.1\n",
      "  Attempting uninstall: google-cloud-bigquery\n",
      "    Found existing installation: google-cloud-bigquery 1.24.0\n",
      "    Uninstalling google-cloud-bigquery-1.24.0:\n",
      "      Successfully uninstalled google-cloud-bigquery-1.24.0\n",
      "  Attempting uninstall: cachetools\n",
      "    Found existing installation: cachetools 4.0.0\n",
      "    Uninstalling cachetools-4.0.0:\n",
      "      Successfully uninstalled cachetools-4.0.0\n",
      "  Attempting uninstall: google-cloud-datastore\n",
      "    Found existing installation: google-cloud-datastore 1.10.0\n",
      "    Uninstalling google-cloud-datastore-1.10.0:\n",
      "      Successfully uninstalled google-cloud-datastore-1.10.0\n",
      "  Attempting uninstall: google-cloud-pubsub\n",
      "    Found existing installation: google-cloud-pubsub 1.3.0\n",
      "    Uninstalling google-cloud-pubsub-1.3.0:\n",
      "      Successfully uninstalled google-cloud-pubsub-1.3.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.9.0\n",
      "    Uninstalling absl-py-0.9.0:\n",
      "      Successfully uninstalled absl-py-0.9.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22.1\n",
      "    Uninstalling scikit-learn-0.22.1:\n",
      "      Successfully uninstalled scikit-learn-0.22.1\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.25.8\n",
      "    Uninstalling urllib3-1.25.8:\n",
      "      Successfully uninstalled urllib3-1.25.8\n",
      "  Attempting uninstall: kubernetes\n",
      "    Found existing installation: kubernetes 10.0.1\n",
      "    Uninstalling kubernetes-10.0.1:\n",
      "      Successfully uninstalled kubernetes-10.0.1\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 1.3.0\n",
      "    Uninstalling cloudpickle-1.3.0:\n",
      "      Successfully uninstalled cloudpickle-1.3.0\n",
      "Successfully installed Deprecated-1.2.7 absl-py-0.8.1 apache-beam-2.17.0 argo-models-2.2.1a0 avro-python3-1.9.2.1 cachetools-3.1.1 cloudpickle-1.1.1 crcmod-1.7 dill-0.3.0 docopt-0.6.2 fastavro-0.21.24 fasteners-0.15 google-apitools-0.5.28 google-cloud-bigquery-1.17.1 google-cloud-bigtable-1.0.0 google-cloud-datastore-1.7.4 google-cloud-pubsub-1.0.2 grpcio-1.27.1 hdfs-2.5.8 httplib2-0.12.0 kfp-0.2.5 kfp-server-api-0.1.40 kubernetes-10.0.0 ml-metadata-0.21.2 mock-2.0.0 monotonic-1.5 oauth2client-3.0.0 pandas-0.25.3 pbr-5.4.4 pyarrow-0.15.1 pymongo-3.10.1 requests-toolbelt-0.9.1 scikit-learn-0.21.3 strip-hints-0.1.8 tabulate-0.8.3 tensorflow-data-validation-0.21.5 tensorflow-model-analysis-0.21.6 tensorflow-transform-0.21.2 tfx-0.21.2 tfx-bsl-0.21.4 urllib3-1.25.7\n",
      "Removing intermediate container b890ca51cb72\n",
      " ---> b923597c8db6\n",
      "Step 4/4 : ENTRYPOINT [\"tfx\"]\n",
      " ---> Running in d5cfc94decfc\n",
      "Removing intermediate container d5cfc94decfc\n",
      " ---> 3c290c186596\n",
      "Successfully built 3c290c186596\n",
      "Successfully tagged gcr.io/mlops-workshop/tfx-cli:latest\n",
      "PUSH\n",
      "Pushing gcr.io/mlops-workshop/tfx-cli:latest\n",
      "The push refers to repository [gcr.io/mlops-workshop/tfx-cli]\n",
      "7548ad4a4720: Preparing\n",
      "39fdca857434: Preparing\n",
      "41b379bf2eb3: Preparing\n",
      "77db3bd6efb2: Preparing\n",
      "07fd8d677a40: Preparing\n",
      "992939e921d8: Preparing\n",
      "a304fb96c494: Preparing\n",
      "431f13f6088f: Preparing\n",
      "f63b09c90bb4: Preparing\n",
      "eac1f876522f: Preparing\n",
      "391d3bae9f0a: Preparing\n",
      "0d69a3a385f0: Preparing\n",
      "dab306330749: Preparing\n",
      "a6c05cf3b0f4: Preparing\n",
      "1c0e7affc630: Preparing\n",
      "1852b2300972: Preparing\n",
      "03c9b9f537a4: Preparing\n",
      "8c98131d2d1d: Preparing\n",
      "cc4590d6a718: Preparing\n",
      "992939e921d8: Waiting\n",
      "a304fb96c494: Waiting\n",
      "431f13f6088f: Waiting\n",
      "f63b09c90bb4: Waiting\n",
      "eac1f876522f: Waiting\n",
      "391d3bae9f0a: Waiting\n",
      "0d69a3a385f0: Waiting\n",
      "dab306330749: Waiting\n",
      "a6c05cf3b0f4: Waiting\n",
      "1c0e7affc630: Waiting\n",
      "1852b2300972: Waiting\n",
      "03c9b9f537a4: Waiting\n",
      "8c98131d2d1d: Waiting\n",
      "cc4590d6a718: Waiting\n",
      "07fd8d677a40: Layer already exists\n",
      "77db3bd6efb2: Layer already exists\n",
      "41b379bf2eb3: Layer already exists\n",
      "a304fb96c494: Layer already exists\n",
      "431f13f6088f: Layer already exists\n",
      "992939e921d8: Layer already exists\n",
      "f63b09c90bb4: Layer already exists\n",
      "eac1f876522f: Layer already exists\n",
      "391d3bae9f0a: Layer already exists\n",
      "0d69a3a385f0: Layer already exists\n",
      "a6c05cf3b0f4: Layer already exists\n",
      "dab306330749: Layer already exists\n",
      "1c0e7affc630: Layer already exists\n",
      "03c9b9f537a4: Layer already exists\n",
      "1852b2300972: Layer already exists\n",
      "39fdca857434: Pushed\n",
      "cc4590d6a718: Layer already exists\n",
      "8c98131d2d1d: Layer already exists\n",
      "7548ad4a4720: Pushed\n",
      "latest: digest: sha256:c61e4faf7bfa6c9b179aa5562d9a68798a68a179842183947ce154fe54653fa0 size: 4297\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                    IMAGES                                   STATUS\n",
      "84439324-8b81-4c2a-9a84-8ead11ec8466  2020-03-26T03:04:02+00:00  5M14S     gs://mlops-workshop_cloudbuild/source/1585191841.89-cb0282d2d9914021a1844280ed1ad9b6.tgz  gcr.io/mlops-workshop/tfx-cli (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --timeout 15m --tag {IMAGE_URI} tfx-cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually triggering CI/CD runs\n",
    "\n",
    "You can manually trigger **Cloud Build** runs using the `gcloud builds submit` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME='tfx_covertype_training_deployment'\n",
    "TAG_NAME='test'\n",
    "TFX_IMAGE_NAME='lab-03-tfx-image'\n",
    "DATA_ROOT_URI='gs://workshop-datasets/covertype/small'\n",
    "MODEL_NAME='tfx_covertype_classifier'\n",
    "PIPELINE_FOLDER='pipeline'\n",
    "PIPELINE_DSL='runner.py'\n",
    "RUNTIME_VERSION='2.1'\n",
    "PYTHON_VERSION='3.7'\n",
    "\n",
    "SUBSTITUTIONS=\"\"\"\n",
    "_ENDPOINT={},\\\n",
    "_GCP_REGION={},\\\n",
    "_ARTIFACT_STORE_URI={},\\\n",
    "_TFX_IMAGE_NAME={},\\\n",
    "_DATA_ROOT_URI={},\\\n",
    "_MODEL_NAME={},\\\n",
    "TAG_NAME={},\\\n",
    "_PIPELINE_FOLDER={},\\\n",
    "_PIPELINE_DSL={},\\\n",
    "_PIPELINE_NAME={},\\\n",
    "_RUNTIME_VERSION={},\\\n",
    "_PYTHON_VERSION={}\n",
    "\"\"\".format(ENDPOINT, \n",
    "           GCP_REGION, \n",
    "           ARTIFACT_STORE_URI, \n",
    "           TFX_IMAGE_NAME,\n",
    "           DATA_ROOT_URI,\n",
    "           MODEL_NAME,\n",
    "           TAG_NAME, \n",
    "           PIPELINE_FOLDER,\n",
    "           PIPELINE_DSL,\n",
    "           PIPELINE_NAME,\n",
    "           RUNTIME_VERSION,\n",
    "           PYTHON_VERSION\n",
    "           ).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 19 file(s) totalling 113.5 KiB before compression.\n",
      "Uploading tarball of [.] to [gs://mlops-workshop_cloudbuild/source/1585192185.61-ca3629c0ba7441a0b640a9e9fb681fd4.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/mlops-workshop/builds/4f0e14be-e100-4346-ada6-5c22aebc2f45].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/4f0e14be-e100-4346-ada6-5c22aebc2f45?project=745302968357].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"4f0e14be-e100-4346-ada6-5c22aebc2f45\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://mlops-workshop_cloudbuild/source/1585192185.61-ca3629c0ba7441a0b640a9e9fb681fd4.tgz#1585192186105856\n",
      "Copying gs://mlops-workshop_cloudbuild/source/1585192185.61-ca3629c0ba7441a0b640a9e9fb681fd4.tgz#1585192186105856...\n",
      "/ [1 files][ 22.1 KiB/ 22.1 KiB]                                                \n",
      "Operation completed over 1 objects/22.1 KiB.                                     \n",
      "BUILD\n",
      "Starting Step #0\n",
      "Step #0: Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Step #0: Sending build context to Docker daemon   42.5kB\n",
      "Step #0: Step 1/4 : FROM tensorflow/tfx:0.21.2\n",
      "Step #0: 0.21.2: Pulling from tensorflow/tfx\n",
      "Step #0: fe703b657a32: Pulling fs layer\n",
      "Step #0: f9df1fafd224: Pulling fs layer\n",
      "Step #0: a645a4b887f9: Pulling fs layer\n",
      "Step #0: 57db7fe0b522: Pulling fs layer\n",
      "Step #0: b11ab658a92d: Pulling fs layer\n",
      "Step #0: 16211b60a645: Pulling fs layer\n",
      "Step #0: 3bb944b07b6e: Pulling fs layer\n",
      "Step #0: 791f84056415: Pulling fs layer\n",
      "Step #0: 3d7f8829d670: Pulling fs layer\n",
      "Step #0: 63c6308d7125: Pulling fs layer\n",
      "Step #0: e7076ce00cca: Pulling fs layer\n",
      "Step #0: 084f6df051b9: Pulling fs layer\n",
      "Step #0: 57db7fe0b522: Waiting\n",
      "Step #0: b11ab658a92d: Waiting\n",
      "Step #0: 16211b60a645: Waiting\n",
      "Step #0: 3bb944b07b6e: Waiting\n",
      "Step #0: 791f84056415: Waiting\n",
      "Step #0: 3d7f8829d670: Waiting\n",
      "Step #0: 63c6308d7125: Waiting\n",
      "Step #0: e7076ce00cca: Waiting\n",
      "Step #0: 084f6df051b9: Waiting\n",
      "Step #0: f9df1fafd224: Verifying Checksum\n",
      "Step #0: f9df1fafd224: Download complete\n",
      "Step #0: a645a4b887f9: Verifying Checksum\n",
      "Step #0: a645a4b887f9: Download complete\n",
      "Step #0: fe703b657a32: Verifying Checksum\n",
      "Step #0: fe703b657a32: Download complete\n",
      "Step #0: 57db7fe0b522: Verifying Checksum\n",
      "Step #0: 57db7fe0b522: Download complete\n",
      "Step #0: 16211b60a645: Verifying Checksum\n",
      "Step #0: 16211b60a645: Download complete\n",
      "Step #0: 3bb944b07b6e: Verifying Checksum\n",
      "Step #0: 3bb944b07b6e: Download complete\n",
      "Step #0: b11ab658a92d: Verifying Checksum\n",
      "Step #0: b11ab658a92d: Download complete\n",
      "Step #0: 3d7f8829d670: Verifying Checksum\n",
      "Step #0: 3d7f8829d670: Download complete\n",
      "Step #0: e7076ce00cca: Verifying Checksum\n",
      "Step #0: e7076ce00cca: Download complete\n",
      "Step #0: 63c6308d7125: Verifying Checksum\n",
      "Step #0: 63c6308d7125: Download complete\n",
      "Step #0: 084f6df051b9: Verifying Checksum\n",
      "Step #0: 084f6df051b9: Download complete\n",
      "Step #0: 791f84056415: Download complete\n",
      "Step #0: fe703b657a32: Pull complete\n",
      "Step #0: f9df1fafd224: Pull complete\n",
      "Step #0: a645a4b887f9: Pull complete\n",
      "Step #0: 57db7fe0b522: Pull complete\n",
      "Step #0: b11ab658a92d: Pull complete\n",
      "Step #0: 16211b60a645: Pull complete\n",
      "Step #0: 3bb944b07b6e: Pull complete\n",
      "Step #0: 791f84056415: Pull complete\n",
      "Step #0: 3d7f8829d670: Pull complete\n",
      "Step #0: 63c6308d7125: Pull complete\n",
      "Step #0: e7076ce00cca: Pull complete\n",
      "Step #0: 084f6df051b9: Pull complete\n",
      "Step #0: Digest: sha256:57bb5d63a6a73912fcf821b91e2e5bc0ab7f730201038b407a644d182769d075\n",
      "Step #0: Status: Downloaded newer image for tensorflow/tfx:0.21.2\n",
      "Step #0:  ---> 131efa6e43e7\n",
      "Step #0: Step 2/4 : WORKDIR /pipeline\n",
      "Step #0:  ---> Running in 55e813fdf8c7\n",
      "Step #0: Removing intermediate container 55e813fdf8c7\n",
      "Step #0:  ---> b6a9ae80df79\n",
      "Step #0: Step 3/4 : COPY ./ ./\n",
      "Step #0:  ---> 8925ddb98c90\n",
      "Step #0: Step 4/4 : ENV PYTHONPATH=\"/pipeline:${PYTHONPATH}\"\n",
      "Step #0:  ---> Running in 27a69ba58169\n",
      "Step #0: Removing intermediate container 27a69ba58169\n",
      "Step #0:  ---> 33224caa7825\n",
      "Step #0: Successfully built 33224caa7825\n",
      "Step #0: Successfully tagged gcr.io/mlops-workshop/lab-03-tfx-image:test\n",
      "Finished Step #0\n",
      "Starting Step #1\n",
      "Step #1: Pulling image: gcr.io/mlops-workshop/tfx-cli\n",
      "Step #1: Using default tag: latest\n",
      "Step #1: latest: Pulling from mlops-workshop/tfx-cli\n",
      "Step #1: 423ae2b273f4: Already exists\n",
      "Step #1: de83a2304fa1: Already exists\n",
      "Step #1: f9a83bce3af0: Already exists\n",
      "Step #1: b6b53be908de: Already exists\n",
      "Step #1: b2712ee52c8a: Pulling fs layer\n",
      "Step #1: ea5f203ec613: Pulling fs layer\n",
      "Step #1: 03c59c37590c: Pulling fs layer\n",
      "Step #1: 7f1f0de4c26d: Pulling fs layer\n",
      "Step #1: acbb498b3663: Pulling fs layer\n",
      "Step #1: e902a9253d07: Pulling fs layer\n",
      "Step #1: f840da7abf6f: Pulling fs layer\n",
      "Step #1: 7df56b5a1b90: Pulling fs layer\n",
      "Step #1: a2724a388c5b: Pulling fs layer\n",
      "Step #1: 444a423384b3: Pulling fs layer\n",
      "Step #1: c8782b778b9f: Pulling fs layer\n",
      "Step #1: 8e8ac5d0d6f3: Pulling fs layer\n",
      "Step #1: 455723d7f082: Pulling fs layer\n",
      "Step #1: 138512ed3a8f: Pulling fs layer\n",
      "Step #1: b5408ba94012: Pulling fs layer\n",
      "Step #1: 7f1f0de4c26d: Waiting\n",
      "Step #1: acbb498b3663: Waiting\n",
      "Step #1: e902a9253d07: Waiting\n",
      "Step #1: f840da7abf6f: Waiting\n",
      "Step #1: 7df56b5a1b90: Waiting\n",
      "Step #1: a2724a388c5b: Waiting\n",
      "Step #1: 444a423384b3: Waiting\n",
      "Step #1: c8782b778b9f: Waiting\n",
      "Step #1: 8e8ac5d0d6f3: Waiting\n",
      "Step #1: 455723d7f082: Waiting\n",
      "Step #1: 138512ed3a8f: Waiting\n",
      "Step #1: b5408ba94012: Waiting\n",
      "Step #1: 03c59c37590c: Verifying Checksum\n",
      "Step #1: 03c59c37590c: Download complete\n",
      "Step #1: ea5f203ec613: Verifying Checksum\n",
      "Step #1: ea5f203ec613: Download complete\n",
      "Step #1: acbb498b3663: Verifying Checksum\n",
      "Step #1: acbb498b3663: Download complete\n",
      "Step #1: 7f1f0de4c26d: Verifying Checksum\n",
      "Step #1: 7f1f0de4c26d: Download complete\n",
      "Step #1: e902a9253d07: Verifying Checksum\n",
      "Step #1: e902a9253d07: Download complete\n",
      "Step #1: f840da7abf6f: Verifying Checksum\n",
      "Step #1: f840da7abf6f: Download complete\n",
      "Step #1: a2724a388c5b: Verifying Checksum\n",
      "Step #1: a2724a388c5b: Download complete\n",
      "Step #1: 7df56b5a1b90: Verifying Checksum\n",
      "Step #1: 7df56b5a1b90: Download complete\n",
      "Step #1: 444a423384b3: Verifying Checksum\n",
      "Step #1: 444a423384b3: Download complete\n",
      "Step #1: 8e8ac5d0d6f3: Verifying Checksum\n",
      "Step #1: 8e8ac5d0d6f3: Download complete\n",
      "Step #1: 455723d7f082: Verifying Checksum\n",
      "Step #1: 455723d7f082: Download complete\n",
      "Step #1: b2712ee52c8a: Verifying Checksum\n",
      "Step #1: b2712ee52c8a: Download complete\n",
      "Step #1: 138512ed3a8f: Verifying Checksum\n",
      "Step #1: 138512ed3a8f: Download complete\n",
      "Step #1: b5408ba94012: Verifying Checksum\n",
      "Step #1: b5408ba94012: Download complete\n",
      "Step #1: c8782b778b9f: Verifying Checksum\n",
      "Step #1: c8782b778b9f: Download complete\n",
      "Step #1: b2712ee52c8a: Pull complete\n",
      "Step #1: ea5f203ec613: Pull complete\n",
      "Step #1: 03c59c37590c: Pull complete\n",
      "Step #1: 7f1f0de4c26d: Pull complete\n",
      "Step #1: acbb498b3663: Pull complete\n",
      "Step #1: e902a9253d07: Pull complete\n",
      "Step #1: f840da7abf6f: Pull complete\n",
      "Step #1: 7df56b5a1b90: Pull complete\n",
      "Step #1: a2724a388c5b: Pull complete\n",
      "Step #1: 444a423384b3: Pull complete\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit . --config cloudbuild.yaml --substitutions {SUBSTITUTIONS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up GitHub integration\n",
    "\n",
    "In this exercise you integrate your CI/CD workflow with **GitHub**, using [Cloud Build GitHub App](https://github.com/marketplace/google-cloud-build). \n",
    "You will set up a trigger that starts the CI/CD workflow when a new tag is applied to the **GitHub** repo managing the  pipeline source code. You will use a fork of this repo as your source GitHub repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a fork of this repo\n",
    "[Follow the GitHub documentation](https://help.github.com/en/github/getting-started-with-github/fork-a-repo) to fork this repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a **Cloud Build** trigger\n",
    "\n",
    "Connect the fork you created in the previous step to your Google Cloud project and create a trigger following the steps in the [Creating GitHub app trigger](https://cloud.google.com/cloud-build/docs/create-github-app-triggers) article. Use the following values on the **Edit trigger** form:\n",
    "\n",
    "|Field|Value|\n",
    "|-----|-----|\n",
    "|Name|[YOUR TRIGGER NAME]|\n",
    "|Description|[YOUR TRIGGER DESCRIPTION]|\n",
    "|Event| Tag|\n",
    "|Source| [YOUR FORK]|\n",
    "|Tag (regex)|.\\*|\n",
    "|Build Configuration|Cloud Build configuration file (yaml or json)|\n",
    "|Cloud Build configuration file location|/ workshops/tfx-caip-tf21/lab-03-tfx-cicd/cloudbuild.yaml|\n",
    "\n",
    "\n",
    "Use the following values for the substitution variables:\n",
    "\n",
    "|Variable|Value|\n",
    "|--------|-----|\n",
    "|_ENDPOINT|[Your inverting proxy host]|\n",
    "|_TFX_IMAGE_NAME|lab-03-tfx-image|\n",
    "|_PIPELINE_NAME|tfx_covertype_training_deployment|\n",
    "|_PIPELINE_DSL|runner.py|\n",
    "|_DATA_ROOT_URI|gs://workshop-datasets/covertype/small|\n",
    "|_PIPELINE_FOLDER|workshops/tfx-caip-tf21/lab-03-tfx-cicd/pipeline|\n",
    "|_PYTHON_VERSION|3.7|\n",
    "|_RUNTIME_VERSION|2.1|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigger the build\n",
    "\n",
    "To start an automated build [create a new release of the repo in GitHub](https://help.github.com/en/github/administering-a-repository/creating-releases). Alternatively, you can start the build by applying a tag using `git`. \n",
    "```\n",
    "git tag [TAG NAME]\n",
    "git push origin --tags\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tfx pipeline list --endpoint={ENDPOINT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tfx run create --pipeline_name={PIPELINE_NAME} --endpoint={ENDPOINT}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
